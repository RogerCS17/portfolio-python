{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0zNOw+TbNn+tayZ2/7ZB1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RogerCS17/portfolio-python/blob/main/Big%20Data/Spark/exercises_spark01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SparkSession"
      ],
      "metadata": {
        "id": "BYYmkuTdW0S2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Teoría"
      ],
      "metadata": {
        "id": "BG_ubnoJgKvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalación de PySpark en Google Colab\n",
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yc3V_1fXDjf",
        "outputId": "1219fa43-598f-44d9-99f1-60b229e04dc3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos la librería\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Creamos una sesión de spark\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "\n",
        "# Mostramos el resultado\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "JYiJhbKqe4dX",
        "outputId": "147ad2a8-48d8-47fb-9485-59dd1228da12"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7bcc2a9e4130>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://0aee4c246673:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos el SparkContext\n",
        "# Punto de entrada para cualquier funcionalidad de Spark\n",
        "sc = spark.sparkContext\n",
        "\n",
        "# Mostramos el resultado\n",
        "sc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "24ycjapTXXRK",
        "outputId": "8093813e-8c5e-4fb1-c3cf-eb18a4afebae"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SparkContext master=local[*] appName=pyspark-shell>"
            ],
            "text/html": [
              "\n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://0aee4c246673:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un RDD\n",
        "# RDD: Estructura de Datos fundamental en Spark\n",
        "# RDD vacío\n",
        "rdd_empty = sc.emptyRDD\n",
        "\n",
        "# Mostramos el resultado\n",
        "rdd_empty"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "MoXLHMc5aWw9",
        "outputId": "aeea8634-1464-41ce-814e-29311c9634d2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method SparkContext.emptyRDD of <SparkContext master=local[*] appName=pyspark-shell>>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.context.SparkContext.emptyRDD</b><br/>def emptyRDD() -&gt; RDD[Any]</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/pyspark/context.py</a>Create an :class:`RDD` that has no partitions or elements.\n",
              "\n",
              ".. versionadded:: 1.5.0\n",
              "\n",
              "Returns\n",
              "-------\n",
              ":class:`RDD`\n",
              "    An empty RDD\n",
              "\n",
              "Examples\n",
              "--------\n",
              "&gt;&gt;&gt; sc.emptyRDD()\n",
              "EmptyRDD...\n",
              "&gt;&gt;&gt; sc.emptyRDD().count()\n",
              "0</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 671);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos un RDD con parallelize\n",
        "# parallelize: Convierte uan colección de Python en RDD\n",
        "# Primer argumento: La colección\n",
        "# Segundo argumento: Las particiones\n",
        "rdd_empty01 = sc.parallelize([], 3)\n",
        "\n",
        "# Obtenemos el número de particiones de nuestro RDD\n",
        "# Mostramos el resultado\n",
        "rdd_empty01.getNumPartitions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knrCpNqvarE9",
        "outputId": "c2d844fd-9441-4895-cc2b-aa4dfe0f7360"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos otro RDD con datos\n",
        "rdd = sc.parallelize([1,2,3,4,5])\n",
        "\n",
        "# Mostramos el resultado\n",
        "rdd.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJROSKHvbeh4",
        "outputId": "19537413-c182-4ab8-bfbf-0d1740873a3f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 5]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un RDD desde un archivo de texto\n",
        "rdd_text_file = sc.textFile(\"./rdd_source.txt\")\n",
        "\n",
        "# Mostramos el resultado\n",
        "rdd_text_file.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yw64xT7Tb6Z5",
        "outputId": "c451fae8-579c-48f4-93cd-9d7589160dc2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Así podemos crear', 'un RDD desde un', 'archivo de texto!!!']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos un RDD donde el archivo de texto sea solo un registro\n",
        "rdd_full_text_file = sc.wholeTextFiles(\"./rdd_source.txt\")\n",
        "\n",
        "# Mostramos el resultado\n",
        "rdd_full_text_file.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZytzQT8cUHy",
        "outputId": "3a9cfdfa-e356-4593-ada2-90eb7c788644"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('file:/content/rdd_source.txt',\n",
              "  'Así podemos crear\\nun RDD desde un\\narchivo de texto!!!')]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un RDD a partir de uno existente\n",
        "rdd_add = rdd.map(lambda x: x+1)\n",
        "\n",
        "# Mostramos el resultado\n",
        "rdd_add.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGndQuDoctMC",
        "outputId": "4a836629-d7a0-4d61-f012-7e610c76fcd5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 3, 4, 5, 6]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un RDD a partir de un DataFrame\n",
        "df = spark.createDataFrame([(1, \"Roger\"), (2, \"Omar\")], [\"id\", \"nombre\"])\n",
        "\n",
        "# Mostramos el resultado\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tScIYltdD3h",
        "outputId": "8e679db6-0bd3-46c3-f9c5-23bb473d05b7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+\n",
            "| id|nombre|\n",
            "+---+------+\n",
            "|  1| Roger|\n",
            "|  2|  Omar|\n",
            "+---+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejercicios"
      ],
      "metadata": {
        "id": "B0o5klk6gMeO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Cree una sesión de Spark con nombre Cap2 y asegúrese de que emplea todos los cores disponibles para ejecutar en su ambiente de trabajo."
      ],
      "metadata": {
        "id": "_iJYK3VJgPKi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos la librería\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Creamos una sesión de spark\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "sc = spark.sparkContext"
      ],
      "metadata": {
        "id": "IrcQ_JCqgR-3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Cree dos RDD vacíos, uno de ellos no debe contener particiones y el otro debe tener 5 particiones. Utilice vías diferentes para crear cada RDD."
      ],
      "metadata": {
        "id": "u8FOmE-Zgemi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RDD vacío sin particiones\n",
        "rdd01 = sc.emptyRDD\n",
        "\n",
        "# RDD vacío con 5 particiones\n",
        "rdd02 = sc.parallelize([], 5)"
      ],
      "metadata": {
        "id": "AAnK4th1ghbF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Cree un RDD que contenga los números primos que hay entre 1 y 20."
      ],
      "metadata": {
        "id": "SvsS0x43h3cp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hallamos los número primos del 1 al 20\n",
        "# Lista de primos\n",
        "list_prime_numbers = [2,3,5,7,11,13,17,19]\n",
        "\n",
        "# Creamos el RDD\n",
        "rdd_prime = sc.parallelize(list_prime_numbers)\n",
        "\n",
        "# Mostramos el resultado\n",
        "rdd_prime.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XEq0jn3h40U",
        "outputId": "0dce6e6b-4a94-4eea-cf5d-905f256dc431"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 3, 5, 7, 11, 13, 17, 19]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Cree un nuevo RDD a partir del RDD creado en el ejercicio anterior el cuál solo contenga los números primos mayores a 10."
      ],
      "metadata": {
        "id": "pOV9k0QuqNDL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtramos a partir del rdd creado anteriormente\n",
        "rdd_greater_than_10 = rdd_prime.filter(lambda x: x > 10)\n",
        "\n",
        "# Mostramos el resultado\n",
        "rdd_greater_than_10.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkqVQAZxqKSg",
        "outputId": "dc4bf42e-0254-48c9-e1c9-2605fe5d1df3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[11, 13, 17, 19]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Cree un RDD a partir de este archivo de texto en donde todo el documento esté contenido en un solo registro. ¿Cómo podría saber la dirección donde está guardado el archivo de texto a partir del RDD creado?"
      ],
      "metadata": {
        "id": "9E0sRkn-sH1W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Con el método wholeTextFiles obtenemos todo como un solo registro\n",
        "# con su dirección\n",
        "rdd_full_doc_text = sc.wholeTextFiles(\"./el_valor_del_big_data.txt\")\n",
        "\n",
        "# Mostramos el resultado\n",
        "rdd_full_doc_text.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCOmvyy4s2pg",
        "outputId": "4c13fda9-3b1b-4ffb-aff2-ad486a4d3a9c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('file:/content/el_valor_del_big_data.txt',\n",
              "  'El valor y la realidad de big data\\r\\nEn los últimos años, han surgido otras \"dos V\": valor y veracidad. Los datos poseen un valor intrínseco. Sin embargo, no tienen ninguna utilidad hasta que dicho valor se descubre. Resulta igualmente importante: ¿cuál es la veracidad de sus datos y cuánto puede confiar en ellos?\\r\\n\\r\\nHoy en día, el big data se ha convertido en un activo crucial. Piense en algunas de las mayores empresas tecnológicas del mundo. Gran parte del valor que ofrecen procede de sus datos, que analizan constantemente para generar una mayor eficiencia y desarrollar nuevos productos.\\r\\n\\r\\nAvances tecnológicos recientes han reducido exponencialmente el coste del almacenamiento y la computación de datos, haciendo que almacenar datos resulte más fácil y barato que nunca. Actualmente, con un mayor volumen de big data más barato y accesible, puede tomar decisiones empresariales más acertadas y precisas.\\r\\n\\r\\nIdentificar el valor del big data no pasa solo por analizarlo (que es ya una ventaja en sí misma). Se trata de todo un proceso de descubrimiento que requiere que los analistas, usuarios empresariales y ejecutivos se planteen las preguntas correctas, identifiquen patrones, formulen hipótesis informadas y predigan comportamientos.')]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Si necesitara crear un RDD a partir del archivo de texto cargado previamente en donde cada línea del archivo fuera un registro del RDD, ¿cómo lo haría?"
      ],
      "metadata": {
        "id": "0WwxKTOosKmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Con el método textFile(), cada línea del archivo, es un registro\n",
        "rdd_doc_text = sc.textFile(\"./el_valor_del_big_data.txt\")\n",
        "\n",
        "# Mostramos el resultado\n",
        "rdd_doc_text.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "np6JTkKmtSuo",
        "outputId": "35c6e0f0-b926-4d43-9380-731fe7e224be"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['El valor y la realidad de big data',\n",
              " 'En los últimos años, han surgido otras \"dos V\": valor y veracidad. Los datos poseen un valor intrínseco. Sin embargo, no tienen ninguna utilidad hasta que dicho valor se descubre. Resulta igualmente importante: ¿cuál es la veracidad de sus datos y cuánto puede confiar en ellos?',\n",
              " '',\n",
              " 'Hoy en día, el big data se ha convertido en un activo crucial. Piense en algunas de las mayores empresas tecnológicas del mundo. Gran parte del valor que ofrecen procede de sus datos, que analizan constantemente para generar una mayor eficiencia y desarrollar nuevos productos.',\n",
              " '',\n",
              " 'Avances tecnológicos recientes han reducido exponencialmente el coste del almacenamiento y la computación de datos, haciendo que almacenar datos resulte más fácil y barato que nunca. Actualmente, con un mayor volumen de big data más barato y accesible, puede tomar decisiones empresariales más acertadas y precisas.',\n",
              " '',\n",
              " 'Identificar el valor del big data no pasa solo por analizarlo (que es ya una ventaja en sí misma). Se trata de todo un proceso de descubrimiento que requiere que los analistas, usuarios empresariales y ejecutivos se planteen las preguntas correctas, identifiquen patrones, formulen hipótesis informadas y predigan comportamientos.']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}